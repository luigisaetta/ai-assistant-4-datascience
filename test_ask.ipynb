{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6791c0d7-3c4f-4277-9bde-e16a3d607eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading the dataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bb8ade-3d87-4666-b609-fa3ed99bba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCIGenaiMagics extension loaded...\n",
      "List of magic commands available:\n",
      "ask\n",
      "ask_code\n",
      "ask_data\n",
      "clear_history\n",
      "show_variables\n",
      "show_model_config\n"
     ]
    }
   ],
   "source": [
    "# load the magic extension\n",
    "%load_ext oci_genai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f0772a-1bc1-4840-bb23-97afd461d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration defined in config.py:\n",
      "* Model:  meta.llama-3.1-70b-instruct\n",
      "* Endpoint:  https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com\n",
      "* Temperature:  0.1\n",
      "* Max_tokens:  1024\n"
     ]
    }
   ],
   "source": [
    "%show_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906216c7-f889-417a-ab36-1db669fdc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask Create a report on Larry Ellison. Limit to 5 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b38f30-2502-4dec-aefd-97c424f16878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask \"is he a sailor?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d9ae0-a604-45b4-82f2-b84dfa412a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%clear_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05710634-5d8b-479a-a24e-17b00bec4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask \"is he a sailor?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a4bf0-caa2-448e-bf66-2e7295533484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"Naples\", \"Rome\", \"Treviso\", \"London\", \"New York\"]\n",
    "counts = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153820f7-9f39-43df-b767-af544b6b245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyze the cities list and print only names of cities in UK. \\\n",
    "Print the names in alphabetical order. \\\n",
    "Count the number of italian cities in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500e8c5-cd93-40a0-a420-d83370024ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Sum all the values in counts and print the result.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d90fa5-d6a9-4837-8eb4-b9f67a70f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ad1e1d-5a7f-4370-af7b-7e64d95d5b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-defined variables in the current session:\n",
      "* titanic:      survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "0      man        True  NaN  Southampton    no  False  \n",
      "1    woman       False    C    Cherbourg   yes  False  \n",
      "2    woman       False  NaN  Southampton   yes   True  \n",
      "3    woman       False    C  Southampton   yes  False  \n",
      "4      man        True  NaN  Southampton    no   True  \n",
      "..     ...         ...  ...          ...   ...    ...  \n",
      "886    man        True  NaN  Southampton    no   True  \n",
      "887  woman       False    B  Southampton   yes   True  \n",
      "888  woman       False  NaN  Southampton    no  False  \n",
      "889    man        True    C    Cherbourg   yes   True  \n",
      "890    man        True  NaN   Queenstown    no   True  \n",
      "\n",
      "[891 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "%show_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e3ec3-ea3e-4395-bbdb-5e4aecfc3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyze the titanic dataset and provide a detailed report.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed45bc7-8b0c-4e48-badf-63fe2636457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"How many records and columns are in the titanic dataframe?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a84536-a299-4953-8e43-415f8823191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyse the titanic dataset, show the correlation matrix.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd13c54-3623-47cf-b5df-fca22edfe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another famous dataset\n",
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74129c7-7919-4fbb-84f3-4d481181a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyze the iris dataset and provide a detailed report.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e197cd-1d8f-4d4e-8314-b94e329b37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyze the iris dataset. Do you think it is possible to identify the species from the features?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e02d5b-5b5d-4366-a0a0-e3d8f4ef9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask_data \"Analyze the iris dataset. Can you suggest to remove some features as redundant?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1384e2c-171c-4cec-83ab-b86f35dafd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "from catboost import CatBoostClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "\n",
      "# Define features (X) and target (y)\n",
      "X = titanic.drop(['survived', 'alive'], axis=1)  # Drop target variables\n",
      "y = titanic['survived']\n",
      "\n",
      "# Convert categorical variables to categorical type\n",
      "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
      "X[categorical_cols] = X[categorical_cols].apply(lambda x: x.astype('category'))\n",
      "\n",
      "# Split data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Initialize CatBoostClassifier\n",
      "model = CatBoostClassifier(iterations=100, random_state=42)\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions on the test set\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Evaluate the model\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "print(\"Classification Report:\")\n",
      "print(classification_report(y_test, y_pred))\n",
      "print(\"Confusion Matrix:\")\n",
      "print(confusion_matrix(y_test, y_pred))\n",
      "```\n",
      "\n",
      "This code trains a CatBoost classification model on the Titanic dataset to predict survival. It first defines the features (X) and target (y), then converts categorical variables to categorical type. The data is split into training and testing sets, and the model is trained on the training set. Finally, the model is evaluated on the test set using accuracy score, classification report, and confusion matrix."
     ]
    }
   ],
   "source": [
    "%ask_code \"Give me the code to train a classification model on titanic dataset, using catboost, to predict survival. Add comments to the code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079cd9b9-703d-413c-94d1-1cc354d3d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "from catboost import CatBoostClassifier, Pool\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "\n",
      "# Define features (X) and target (y)\n",
      "X = titanic.drop(['survived', 'alive'], axis=1)  # Drop target variables\n",
      "y = titanic['survived']\n",
      "\n",
      "# Identify categorical columns\n",
      "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
      "\n",
      "# Create a CatBoost Pool with categorical features\n",
      "train_pool = Pool(X_train, label=y_train, cat_features=categorical_cols)\n",
      "test_pool = Pool(X_test, label=y_test, cat_features=categorical_cols)\n",
      "\n",
      "# Initialize CatBoostClassifier\n",
      "model = CatBoostClassifier(iterations=100, random_state=42)\n",
      "\n",
      "# Train the model\n",
      "model.fit(train_pool)\n",
      "\n",
      "# Make predictions on the test set\n",
      "y_pred = model.predict(test_pool)\n",
      "\n",
      "# Evaluate the model\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "print(\"Classification Report:\")\n",
      "print(classification_report(y_test, y_pred))\n",
      "print(\"Confusion Matrix:\")\n",
      "print(confusion_matrix(y_test, y_pred))\n",
      "```\n",
      "\n",
      "In this modified code, we create a CatBoost Pool for both the training and testing sets, specifying the categorical features using the `cat_features` parameter. This allows CatBoost to handle the categorical features correctly during training and prediction. Note that we no longer need to convert categorical variables to categorical type using `astype('category')`, as CatBoost handles this internally."
     ]
    }
   ],
   "source": [
    "%ask_code \"modify the code to treat categorical features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77abe902-c02b-4aba-b0bf-8989bbb9d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is CatBoost?**\n",
      "\n",
      "CatBoost is an open-source, gradient boosting on decision trees library developed by Yandex, a Russian technology company. It is designed to handle categorical features and is particularly well-suited for datasets with a mix of numerical and categorical variables. CatBoost is widely used in machine learning competitions and has been employed in various applications, including natural language processing, computer vision, and recommender systems.\n",
      "\n",
      "**Key Features of CatBoost**\n",
      "\n",
      "1. **Handling Categorical Features**: CatBoost is specifically designed to handle categorical features, which are common in many real-world datasets. It uses a technique called \"target encoding\" to convert categorical variables into numerical representations that can be used by the model.\n",
      "2. **Gradient Boosting**: CatBoost uses gradient boosting, a popular ensemble learning technique that combines multiple weak models to create a strong predictive model. Gradient boosting is particularly effective for handling complex interactions between features.\n",
      "3. **Decision Trees**: CatBoost uses decision trees as the base models for gradient boosting. Decision trees are simple, interpretable models that are well-suited for handling categorical features.\n",
      "4. **Ordered Boosting**: CatBoost uses an ordered boosting approach, which means that the model is trained in a sequential manner, with each subsequent model attempting to correct the errors of the previous model.\n",
      "5. **Support for Missing Values**: CatBoost can handle missing values in the data, which is a common problem in many real-world datasets.\n",
      "6. **Support for Large Datasets**: CatBoost is designed to handle large datasets and can scale to millions of rows and thousands of features.\n",
      "7. **Interpretable Models**: CatBoost provides feature importance scores, which can be used to interpret the results of the model and understand the relationships between the features and the target variable.\n",
      "\n",
      "**How CatBoost Works**\n",
      "\n",
      "Here is a high-level overview of how CatBoost works:\n",
      "\n",
      "1. **Data Preparation**: The dataset is prepared by encoding categorical variables using target encoding.\n",
      "2. **Model Initialization**: The model is initialized with a set of decision trees, each with a random subset of features.\n",
      "3. **Gradient Boosting**: The model is trained using gradient boosting, with each subsequent model attempting to correct the errors of the previous model.\n",
      "4. **Ordered Boosting**: The models are trained in a sequential manner, with each subsequent model attempting to correct the errors of the previous model.\n",
      "5. **Prediction**: The final model is used to make predictions on new, unseen data.\n",
      "\n",
      "**Advantages of CatBoost**\n",
      "\n",
      "1. **Handling Categorical Features**: CatBoost is particularly well-suited for datasets with categorical features.\n",
      "2. **Interpretable Models**: CatBoost provides feature importance scores, which can be used to interpret the results of the model.\n",
      "3. **Handling Missing Values**: CatBoost can handle missing values in the data.\n",
      "4. **Scalability**: CatBoost can handle large datasets and scale to millions of rows and thousands of features.\n",
      "\n",
      "**Disadvantages of CatBoost**\n",
      "\n",
      "1. **Computational Cost**: CatBoost can be computationally expensive, particularly for large datasets.\n",
      "2. **Hyperparameter Tuning**: CatBoost has several hyperparameters that need to be tuned, which can be time-consuming.\n",
      "\n",
      "Overall, CatBoost is a powerful library for handling categorical features and is widely used in machine learning competitions and applications."
     ]
    }
   ],
   "source": [
    "%ask What is catboost? Give a detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613bb8f-ed7e-4907-9b34-7284d2a58075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ask \"can you suggest other gradient boosting models?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70412d-f22f-4ec8-9c33-9cfef7b8ba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
